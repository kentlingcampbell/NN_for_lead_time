{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "handled-slide",
   "metadata": {
    "id": "handled-slide"
   },
   "source": [
    "# Arrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-subscriber",
   "metadata": {
    "id": "minimal-subscriber"
   },
   "source": [
    "## Neural Net Predicion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-tonight",
   "metadata": {
    "id": "threaded-tonight"
   },
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-dylan",
   "metadata": {
    "id": "waiting-dylan"
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-eagle",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "id": "understood-eagle",
    "outputId": "34f45976-d17c-431f-9474-2fa045e42078"
   },
   "outputs": [],
   "source": [
    "# import Data\n",
    "Data = pd.read_csv('https://drive.google.com/u/0/uc?id=1V_xIhHtXbB_QbjqNvfiHinLjejhZbqaw&export=download', index_col=0)\n",
    "#Data = pd.read_csv('LEADTIME.csv', index_col=0)\n",
    "print(Data.shape)\n",
    "#Data.head(20).T\n",
    "Data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-adrian",
   "metadata": {
    "id": "material-adrian"
   },
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-involvement",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "neutral-involvement",
    "outputId": "ec55f267-2872-4c5f-9cf2-5fbbff4bd228"
   },
   "outputs": [],
   "source": [
    "#get some information about our Data-Set\n",
    "Data.info()\n",
    "# check if there are any Null values\n",
    "Data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-particle",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "given-particle",
    "outputId": "d39a3cd9-775a-4796-ec25-c784b413a9ed",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(Data.columns)\n",
    "columnList = Data.columns.tolist()\n",
    "print('mfr  = ', len(Data.mfr.unique()))\n",
    "print('icc3 = ', len(Data.icc3.unique()))\n",
    "print('icc2 = ', len(Data.icc2.unique()))\n",
    "print('icc1 = ', len(Data.icc1.unique()))\n",
    "print('mpn  = ', len(Data.mpn.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-arlington",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "honey-arlington",
    "outputId": "6dfafdec-b834-4885-8973-facecfe3f82a"
   },
   "outputs": [],
   "source": [
    "Data.describe().transpose()\n",
    "#Data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-horizontal",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "little-horizontal",
    "outputId": "1660b81d-0a87-486c-cfaa-da3792b74347",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualizing actualleadtime\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "fig.add_subplot(2,1,1)\n",
    "sns.distplot(x=Data['actualleadtime'])\n",
    "fig.add_subplot(2,1,2)\n",
    "sns.boxplot(x=Data['actualleadtime'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-while",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "id": "surprised-while",
    "outputId": "022d669e-ca0f-4e4b-eec2-aa4b35be3030"
   },
   "outputs": [],
   "source": [
    "# visualizing expected_leadtime\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "fig.add_subplot(2,1,1)\n",
    "sns.distplot(x=Data['expected_leadtime'])\n",
    "fig.add_subplot(2,1,2)\n",
    "sns.boxplot(x=Data['expected_leadtime'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-gabriel",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "indie-gabriel",
    "outputId": "ff4971b9-2c87-4097-bbc1-dca9fbf3203e"
   },
   "outputs": [],
   "source": [
    "# Arrow's Expected Leadtime (MAE - MSE - RMSE)\n",
    "print('MAE:      ', metrics.mean_absolute_error(Data['actualleadtime'], Data['expected_leadtime']))  \n",
    "print('MSE:      ', metrics.mean_squared_error(Data['actualleadtime'], Data['expected_leadtime']))  \n",
    "print('RMSE:     ', np.sqrt(metrics.mean_squared_error(Data['actualleadtime'], Data['expected_leadtime'])))\n",
    "print('VarScore: ', metrics.explained_variance_score(Data['actualleadtime'],Data['expected_leadtime']))\n",
    "print('R^2:      ', metrics.r2_score(Data['actualleadtime'], Data['expected_leadtime']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-cleaning",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "continued-cleaning",
    "outputId": "fbd282d6-963b-48ce-bee9-9e757536503a"
   },
   "outputs": [],
   "source": [
    "# visualizing expected_leadtime - continuous\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "sns.scatterplot(x=Data['expected_leadtime'],y=Data['actualleadtime'], alpha=0.1)\n",
    "plt.axis('square')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-montana",
   "metadata": {
    "id": "general-montana"
   },
   "outputs": [],
   "source": [
    "EconData = Data.copy(deep=True)\n",
    "EconData['error_expected_leadtime'] = Data['expected_leadtime'] - Data['actualleadtime']\n",
    "EconData['expected_leadtime_cost'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-broadcasting",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "deluxe-broadcasting",
    "outputId": "cbcb9d65-ef3a-4a81-e19c-440b3419e055"
   },
   "outputs": [],
   "source": [
    "#Error of 'expected'\n",
    "#Negative is too early\n",
    "EconData = Data.copy(deep=True)\n",
    "EconData['error_expected_leadtime'] = Data['expected_leadtime'] - Data['actualleadtime']\n",
    "\n",
    "#Create cost for 'expected_leadtime'\n",
    "EconData['expected_leadtime_cost'] = np.nan\n",
    "\n",
    "for index, row in EconData.iterrows():\n",
    "    if (EconData['error_expected_leadtime'][index] > -1) & (EconData['error_expected_leadtime'][index] < 1): \n",
    "    # -1 to 1 weeks, $0\n",
    "        EconData['expected_leadtime_cost'][index] = 0.00\n",
    "    elif (EconData['error_expected_leadtime'][index] >= 1) & (EconData['error_expected_leadtime'][index] < 2): \n",
    "    # 1 week, $400\n",
    "        EconData['expected_leadtime_cost'][index] = 400.00\n",
    "    elif (EconData['error_expected_leadtime'][index] >= 2) & (EconData['error_expected_leadtime'][index] < 4): \n",
    "    # 2 weeks - 3 weeks, $600\n",
    "        EconData['expected_leadtime_cost'][index] = 600.00  \n",
    "    elif (EconData['error_expected_leadtime'][index] >= 4) & (EconData['error_expected_leadtime'][index] < 8): \n",
    "    # 4 weeks - 7 weeks, $1,000 \n",
    "        EconData['expected_leadtime_cost'][index] = 1000.00\n",
    "    elif (EconData['error_expected_leadtime'][index] >= 8): \n",
    "    # 8 weeks or more, $4,000\n",
    "        EconData['expected_leadtime_cost'][index] = 4000.00      \n",
    "    else: \n",
    "    # all negative weeks (too early), $400/week \n",
    "        EconData['expected_leadtime_cost'][index] = np.floor(abs(EconData['error_expected_leadtime'][index]))*400.00\n",
    "\n",
    "        \n",
    "import locale\n",
    "locale.setlocale( locale.LC_ALL, '' )\n",
    "print('Associated costs from using Expected as warehouse guidance:  ' + str(locale.currency(EconData['expected_leadtime_cost'].sum(), grouping=True )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-priest",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "present-priest",
    "outputId": "86ed4006-1f63-4cc9-f2b9-49f98725092a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualizing PCA - continuous\n",
    "\n",
    "fig = plt.figure(figsize=(16,80))\n",
    "for i,pca in enumerate(columnList[7:]):\n",
    "    name = '%s' %(pca)\n",
    "    counter = 1+i\n",
    "    fig.add_subplot(21,2,counter)\n",
    "    sns.scatterplot(x=Data[name],y=Data['actualleadtime'], alpha=0.25)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-quebec",
   "metadata": {
    "id": "ideal-quebec"
   },
   "source": [
    "## Transform hashed names to human readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-instrumentation",
   "metadata": {
    "id": "suspended-instrumentation"
   },
   "outputs": [],
   "source": [
    "# categorical - convert hashed names to ints\n",
    "\n",
    "mfr_hashes = Data.mfr.unique()\n",
    "mfr_dict = dict(zip(mfr_hashes, range(len(mfr_hashes))))\n",
    "# map ints to hashed names with dictionary\n",
    "Data['mfr'] = Data['mfr'].map(mfr_dict)\n",
    "\n",
    "icc3_hashes = Data.icc3.unique()\n",
    "icc3_dict = dict(zip(icc3_hashes, range(len(icc3_hashes))))\n",
    "# map ints to hashed names with dictionary\n",
    "Data['icc3'] = Data['icc3'].map(icc3_dict)\n",
    "\n",
    "icc2_hashes = Data.icc2.unique()\n",
    "icc2_dict = dict(zip(icc2_hashes, range(len(icc2_hashes))))\n",
    "# map ints to hashed names with dictionary\n",
    "Data['icc2'] = Data['icc2'].map(icc2_dict)\n",
    "\n",
    "icc1_hashes = Data.icc1.unique()\n",
    "icc1_dict = dict(zip(icc1_hashes, range(len(icc1_hashes))))\n",
    "# map ints to hashed names with dictionary\n",
    "Data['icc1'] = Data['icc1'].map(icc1_dict)\n",
    "\n",
    "mpn_hashes = Data.mpn.unique()\n",
    "mpn_dict = dict(zip(mpn_hashes, range(len(mpn_hashes))))\n",
    "# map ints to hashed names with dictionary\n",
    "Data['mpn'] = Data['mpn'].map(mpn_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-senator",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "collective-senator",
    "outputId": "67075a05-dfd1-40d5-ba50-c4b8e6f6b6d4"
   },
   "outputs": [],
   "source": [
    "# visualizing categorical\n",
    "\n",
    "fig = plt.figure(figsize=(15,24))\n",
    "for i,label in enumerate(columnList[:4]):\n",
    "    name = '%s' %(label)\n",
    "    counter = 1+i\n",
    "    fig.add_subplot(4,1,counter)\n",
    "    sns.countplot(x=Data[name])\n",
    "    plt.xticks(rotation=90)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-service",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "described-service",
    "outputId": "af86d48d-a794-4ae7-9ef0-63155645eff7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlations with target\n",
    "\n",
    "print(Data[Data.columns[:]].corr()['actualleadtime'][:].sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-wedding",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "respected-wedding",
    "outputId": "ae0e38b5-bdbb-4f26-9ab8-368e94dd6d7f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr_mat = Data.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr_mat, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr_mat, mask=mask, cmap=cmap, vmax=.5, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-wilson",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "present-wilson",
    "outputId": "7a9c4a9a-e550-4a27-b155-d9db7ca94756",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retain upper triangular values of correlation matrix and \n",
    "# make Lower triangular values Null \n",
    "upper_corr_mat = corr_mat.where(np.triu(np.ones(corr_mat.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Convert to 1-D series and drop Null values \n",
    "unique_corr_pairs = upper_corr_mat.unstack().dropna() \n",
    "\n",
    "# Sort correlation pairs \n",
    "sorted_mat = unique_corr_pairs.sort_values() \n",
    "print(sorted_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-trouble",
   "metadata": {
    "id": "conscious-trouble"
   },
   "source": [
    "## Dataset Preparation for modeling Train - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-sympathy",
   "metadata": {
    "id": "entire-sympathy"
   },
   "outputs": [],
   "source": [
    "X = Data.drop('actualleadtime',axis =1).values\n",
    "y = Data['actualleadtime'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-diabetes",
   "metadata": {
    "id": "compressed-diabetes"
   },
   "outputs": [],
   "source": [
    "#splitting Train and Test \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-payment",
   "metadata": {
    "id": "superior-payment"
   },
   "source": [
    "## Baseline Keras Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-drunk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "attached-drunk",
    "outputId": "42a3023c-7bc4-4ca1-d8a3-ce6db2b512de"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputShape = X_train.shape[1]\n",
    "print(X_train.shape)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "random.seed(10)\n",
    "\n",
    "model1 = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=[inputShape]),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "\n",
    "model1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae',\n",
    ")\n",
    "\n",
    "history1 = model1.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# convert the training history to a dataframe\n",
    "history_df = pd.DataFrame(history1.history)\n",
    "# use Pandas native plot method\n",
    "history_df['loss'].plot();\n",
    "\n",
    "y_pred = model1.predict(X_test)\n",
    "print('MAE:     ', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('MSE:     ', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('RMSE:    ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('VarScore:',metrics.explained_variance_score(y_test,y_pred))\n",
    "print('R^2     :', metrics.r2_score(y_test, y_pred))\n",
    "# Visualizing Our predictions\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_test,y_pred)\n",
    "# Perfect predictions\n",
    "plt.plot(y_test,y_test,'r')\n",
    "\n",
    "#MAE:      6.567314748970678\n",
    "#MSE:      69.34229602211707\n",
    "#RMSE:     8.32720217252572\n",
    "#VarScore: 0.012679280153120365\n",
    "#R^2     : -0.04580826813625527\n",
    "\n",
    "#MAE:      6.5665305169940025\n",
    "#MSE:      75.0684391461496\n",
    "#RMSE:     8.664204472780499\n",
    "#VarScore: 0.033679731998591644\n",
    "#R^2     : -0.13216894794032097\n",
    "\n",
    "#MAE:      6.687301871523192\n",
    "#MSE:      67.04483540831164\n",
    "#RMSE:     8.188091072301996\n",
    "#VarScore: -0.0005407931594825222\n",
    "#R^2     : -0.011158372712129827\n",
    "\n",
    "#MAE:      6.252205755541979\n",
    "#MSE:      65.47076853783466\n",
    "#RMSE:     8.091400900822716\n",
    "#VarScore: 0.04956918355722428\n",
    "#R^2     : 0.0125814259703243\n",
    "\n",
    "#MAE:      6.588257200177496\n",
    "#MSE:      70.9934218506885\n",
    "#RMSE:     8.425759422787273\n",
    "#VarScore: 0.009269269799383695\n",
    "#R^2     : -0.07071025642205653\n",
    "MAE:      6.589789192545757\n",
    "MSE:      70.68138430265022\n",
    "RMSE:     8.407222151379742\n",
    "VarScore: -0.01357110655237026\n",
    "R^2     : -0.06600416120416375\n",
    "[<matplotlib.lines.Line2D at 0x7f0dc42f7a50>]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-replication",
   "metadata": {
    "id": "executive-replication"
   },
   "source": [
    "## Best Keras Neural Net - with extra capacity and early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-xerox",
   "metadata": {
    "id": "stretch-xerox"
   },
   "outputs": [],
   "source": [
    "X = Data.drop('actualleadtime',axis =1).values\n",
    "y = Data['actualleadtime'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-george",
   "metadata": {
    "id": "israeli-george"
   },
   "outputs": [],
   "source": [
    "#splitting Train and Test \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-twist",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "first-twist",
    "outputId": "749daea4-431b-4637-cbc1-69950fad279a"
   },
   "outputs": [],
   "source": [
    "inputShape = X_train.shape[1]\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-solid",
   "metadata": {
    "id": "outside-solid"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "keras.backend.clear_session()\n",
    "random.seed(10)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001,                   # minimium amount of change to count as an improvement\n",
    "    patience=20,                       # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model2 = keras.Sequential([\n",
    "    layers.Dense(1024, activation='relu', input_shape=[inputShape]), \n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-corruption",
   "metadata": {
    "id": "particular-corruption"
   },
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-antique",
   "metadata": {
    "id": "fifty-antique"
   },
   "outputs": [],
   "source": [
    "history2 = model2.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=256,\n",
    "    epochs=500,\n",
    "    callbacks=[early_stopping],        # put your callbacks in a list\n",
    "    verbose=0,                         # turn off training log\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-document",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "aging-document",
    "outputId": "adfd35f8-a647-4d1c-9840-147808574eb6"
   },
   "outputs": [],
   "source": [
    "# convert the training history to a dataframe\n",
    "history_df = pd.DataFrame(history2.history)\n",
    "# use Pandas native plot method\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-kitty",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "opponent-kitty",
    "outputId": "9754c285-1268-4dfa-f4dc-70c90c885ad9"
   },
   "outputs": [],
   "source": [
    "y_pred = model2.predict(X_test)\n",
    "print('MAE:     ', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('MSE:     ', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('RMSE:    ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('VarScore:',metrics.explained_variance_score(y_test,y_pred))\n",
    "print('R^2     :', metrics.r2_score(y_test, y_pred))\n",
    "# Visualizing Our predictions\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_test,y_pred)\n",
    "# Perfect predictions\n",
    "plt.plot(y_test,y_test,'r')\n",
    "\n",
    "#MAE:      5.652554930816247\n",
    "#MSE:      55.68107060033343\n",
    "#RMSE:     7.461974979878546\n",
    "#VarScore: 0.17452890869855564\n",
    "#R^2     : 0.1602279221626297\n",
    "\n",
    "#MAE:      5.6478783102414605\n",
    "#MSE:      56.02362755063129\n",
    "#RMSE:     7.4848932891946625\n",
    "#VarScore: 0.17870092918037417\n",
    "#R^2     : 0.1550615387072164\n",
    "\n",
    "#MAE:      5.662848275504706\n",
    "#MSE:      56.65744416611105\n",
    "#RMSE:     7.527113933381841\n",
    "#VarScore: 0.17237954737159078\n",
    "#R^2     : 0.14550242839538807\n",
    "\n",
    "#MAE:      5.677067341143838\n",
    "#MSE:      56.23021178304301\n",
    "#RMSE:     7.498680669494002\n",
    "#VarScore: 0.1725942642626136\n",
    "#R^2     : 0.1519458717807297\n",
    "\n",
    "#MAE:      5.665296212453778\n",
    "#MSE:      56.84314413868254\n",
    "#RMSE:     7.539439245639064\n",
    "#VarScore: 0.1739490095662677\n",
    "#R^2     : 0.1427017341892718\n",
    "MAE:      5.661731753986324\n",
    "MSE:      56.40033203140934\n",
    "RMSE:     7.5100154481471835\n",
    "VarScore: 0.17293202503610794\n",
    "R^2     : 0.14938014822490508\n",
    "[<matplotlib.lines.Line2D at 0x7f0dbc157650>]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-fishing",
   "metadata": {
    "id": "lasting-fishing"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-trace",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "signal-trace",
    "outputId": "5a836236-72e0-466f-ec20-eb99c780c57c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Categorical feature - APPROACH : create 'merged number (e.g, social security number)' \n",
    "\n",
    "Data['globalNum'] = np.nan\n",
    "\n",
    "for i in range(Data.shape[0]):\n",
    "    Data['globalNum'][i] = int(format(Data['mfr'][i], '03d') + format(Data['icc3'][i], '03d') + \n",
    "                               format(Data['icc2'][i], '02d') + format(Data['icc1'][i], '02d'))\n",
    "\n",
    "print('globalNum  = ', len(Data.globalNum.unique()))\n",
    "#Data[['mfr', 'icc3', 'icc2','icc1','globalNum']].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-momentum",
   "metadata": {
    "id": "bored-momentum",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Categorical feature - APPROACH : create 'counts'                             \n",
    "\n",
    "valueCounts = Data['mfr'].value_counts()    \n",
    "valueCounts.name = 'mfr_counts'\n",
    "Data = Data.join(valueCounts, on='mfr')\n",
    "\n",
    "valueCounts = Data['icc3'].value_counts()    \n",
    "valueCounts.name = 'icc3_counts'\n",
    "Data = Data.join(valueCounts, on='icc3')\n",
    "\n",
    "valueCounts = Data['icc2'].value_counts()    \n",
    "valueCounts.name = 'icc2_counts'\n",
    "Data = Data.join(valueCounts, on='icc2')\n",
    "\n",
    "valueCounts = Data['icc1'].value_counts()    \n",
    "valueCounts.name = 'icc1_counts'\n",
    "Data = Data.join(valueCounts, on='icc1')\n",
    "\n",
    "valueCounts = Data['mpn'].value_counts()    \n",
    "valueCounts.name = 'mpn_counts'\n",
    "Data = Data.join(valueCounts, on='mpn')\n",
    "\n",
    "valueCounts = Data['globalNum'].value_counts()    \n",
    "valueCounts.name = 'globalNum_counts'\n",
    "Data = Data.join(valueCounts, on='globalNum')\n",
    "\n",
    "#Data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-export",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "id": "sonic-export",
    "outputId": "23f2c6b1-ce6e-4849-ca2f-8b13f8f1c4cd"
   },
   "outputs": [],
   "source": [
    "# Categorical feature - QC with NN run\n",
    "X = Data.drop('actualleadtime',axis =1).values\n",
    "y = Data['actualleadtime'].values\n",
    "\n",
    "#splitting Train and Test \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=50)\n",
    "\n",
    "inputShape = X_train.shape[1]\n",
    "print(X_train.shape)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "random.seed(10)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001,                   # minimium amount of change to count as an improvement\n",
    "    patience=20,                       # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model3 = keras.Sequential([\n",
    "    layers.Dense(1024, activation='relu', input_shape=[inputShape]), \n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "\n",
    "model3.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae',\n",
    ")\n",
    "\n",
    "history3 = model3.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=256,\n",
    "    epochs=500,\n",
    "    callbacks=[early_stopping],        # put your callbacks in a list\n",
    "    verbose=0,                         # turn off training log\n",
    ")\n",
    "\n",
    "# convert the training history to a dataframe\n",
    "history_df = pd.DataFrame(history3.history)\n",
    "# use Pandas native plot method\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))\n",
    "\n",
    "y_pred = model3.predict(X_test)\n",
    "print('MAE:     ', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('MSE:     ', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('RMSE:    ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('VarScore:',metrics.explained_variance_score(y_test,y_pred))\n",
    "print('R^2     :', metrics.r2_score(y_test, y_pred))\n",
    "# Visualizing Our predictions\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_test,y_pred)\n",
    "# Perfect predictions\n",
    "plt.plot(y_test,y_test,'r')\n",
    "\n",
    "#(52428, 55)\n",
    "#Minimum validation loss: 6.578306594156533\n",
    "#MAE:      6.5783064010132914\n",
    "#MSE:      68.08410929148032\n",
    "#RMSE:     8.251309550094478\n",
    "#VarScore: 0.0063678189506687355\n",
    "#R^2     : -0.02683251796294761\n",
    "\n",
    "#Minimum validation loss: 6.580244954558053\n",
    "#MAE:      6.5802450677373\n",
    "#MSE:      68.44089438108227\n",
    "#RMSE:     8.272901207018144\n",
    "#VarScore: 0.00516675247150955\n",
    "#R^2     : -0.03221348770375987\n",
    "\n",
    "#(52428, 55)\n",
    "#Minimum validation loss: 6.584634757054665\n",
    "#MAE:      6.585235028169771\n",
    "#MSE:      68.48932255208638\n",
    "#RMSE:     8.275827605266217\n",
    "#VarScore: 0.0038829261789706804\n",
    "#R^2     : -0.032943872830186294\n",
    "\n",
    "#(52428, 55)\n",
    "#Minimum validation loss: 6.5619874945710635\n",
    "#MAE:      6.561987362355801\n",
    "#MSE:      68.12458229036086\n",
    "#RMSE:     8.253761705450483\n",
    "#VarScore: 0.00871068632673544\n",
    "#R^2     : -0.027442924587672834\n",
    "(52428, 55)\n",
    "Minimum validation loss: 6.581878185272217\n",
    "MAE:      6.5818781666000055\n",
    "MSE:      68.46174441464751\n",
    "RMSE:     8.274161251428904\n",
    "VarScore: 0.0050394398516169225\n",
    "R^2     : -0.03252794422949279\n",
    "[<matplotlib.lines.Line2D at 0x7f0dbded3650>]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-background",
   "metadata": {
    "id": "grateful-background"
   },
   "source": [
    "Hurts model big time, but, what changed? Look at correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-horror",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "separate-horror",
    "outputId": "bdfb9eca-ac6c-44de-8647-eb74c30336dd"
   },
   "outputs": [],
   "source": [
    "# Print correlations with target\n",
    "print(Data[Data.columns[:]].corr()['actualleadtime'][:].sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-opening",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "julian-opening",
    "outputId": "f5d9f3e3-2b72-492e-bf96-67afd8a4e819"
   },
   "outputs": [],
   "source": [
    "# Create subset of best correlated features\n",
    "Datadeepcopy = Data.copy(deep=True)\n",
    "\n",
    "good_correlations = Data[Data.columns[:]].corr()['actualleadtime'][:].sort_values()\n",
    "good_corr_keys = good_correlations[abs(good_correlations) > 0.05].keys()\n",
    "print(good_corr_keys.shape)\n",
    "print(good_corr_keys)\n",
    "Data_corr = Data[good_corr_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-potato",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "mobile-potato",
    "outputId": "c061dbdb-0c66-40e1-e35b-36011b1f5dd7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RERUN NN with categorical standardization step with reduced features from correlations - QC\n",
    "X = Data_corr.drop('actualleadtime',axis =1).values\n",
    "y = Data_corr['actualleadtime'].values\n",
    "\n",
    "#splitting Train and Test \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=50)\n",
    "\n",
    "inputShape = X_train.shape[1]\n",
    "print(X_train.shape)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "random.seed(10)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001,                   # minimium amount of change to count as an improvement\n",
    "    patience=20,                       # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model4 = keras.Sequential([\n",
    "    layers.Dense(1024, activation='relu', input_shape=[inputShape]), \n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "\n",
    "model4.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae',\n",
    ")\n",
    "\n",
    "history4 = model4.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=256,\n",
    "    epochs=500,\n",
    "    callbacks=[early_stopping],        # put your callbacks in a list\n",
    "    verbose=0,                         # turn off training log\n",
    ")\n",
    "\n",
    "# convert the training history to a dataframe\n",
    "history_df = pd.DataFrame(history4.history)\n",
    "# use Pandas native plot method\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))\n",
    "\n",
    "y_pred = model4.predict(X_test)\n",
    "print('MAE:     ', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('MSE:     ', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('RMSE:    ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('VarScore:',metrics.explained_variance_score(y_test,y_pred))\n",
    "print('R^2     :', metrics.r2_score(y_test, y_pred))\n",
    "# Visualizing Our predictions\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_test,y_pred)\n",
    "# Perfect predictions\n",
    "plt.plot(y_test,y_test,'r')\n",
    "\n",
    "#(52428, 9)\n",
    "#Minimum validation loss: 5.394649815539378\n",
    "#MAE:      5.394649885707965\n",
    "#MSE:      52.18399158458135\n",
    "#RMSE:     7.223848806874446\n",
    "#VarScore: 0.22581255892630892\n",
    "#R^2     : 0.21297025056538155\n",
    "\n",
    "#(52428, 9)\n",
    "#Minimum validation loss: 5.435182109526296\n",
    "#MAE:      5.435285187908102\n",
    "#MSE:      54.682551431700176\n",
    "#RMSE:     7.39476513702093\n",
    "#VarScore: 0.21817158964288386\n",
    "#R^2     : 0.17528741200294484\n",
    "\n",
    "#(52428, 9)\n",
    "#Minimum validation loss: 5.472837763028368\n",
    "#MAE:      5.472974350643965\n",
    "#MSE:      54.83584102127504\n",
    "#RMSE:     7.405122620272742\n",
    "#VarScore: 0.20655990802351176\n",
    "#R^2     : 0.17297552547202488\n",
    "\n",
    "#(52428, 9)\n",
    "#Minimum validation loss: 5.4677299398519885\n",
    "#MAE:      5.467729999679463\n",
    "#MSE:      54.68307986610659\n",
    "#RMSE:     7.3948008672381835\n",
    "#VarScore: 0.20336280659293415\n",
    "#R^2     : 0.1752794422485079\n",
    "\n",
    "#(52428, 9)\n",
    "#Minimum validation loss: 5.451549962118633\n",
    "#MAE:      5.451550021591399\n",
    "#MSE:      53.755060736786604\n",
    "#RMSE:     7.331784280568176\n",
    "#VarScore: 0.2139574314112922\n",
    "#R^2     : 0.18927566294073717\n",
    "(52428, 9)\n",
    "Minimum validation loss: 5.472656726837158\n",
    "MAE:      5.4726566950316435\n",
    "MSE:      54.476041767043434\n",
    "RMSE:     7.380788695460901\n",
    "VarScore: 0.20552668555365938\n",
    "R^2     : 0.1784019543117138\n",
    "[<matplotlib.lines.Line2D at 0x7f0dc4948090>]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-procurement",
   "metadata": {
    "id": "enormous-procurement"
   },
   "source": [
    "OK, so it's safe to say we can drop features to get improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-favor",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "constitutional-favor",
    "outputId": "b150d9f0-fe07-4be7-f35c-aaed6ddaf1bf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Numerical feature engineering\n",
    "# PCA standardization step 1 - determine which columns are PCA components\n",
    "#Data.columns\n",
    "Data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-corruption",
   "metadata": {
    "id": "welcome-corruption"
   },
   "outputs": [],
   "source": [
    "# PCA standardization step 2 - create list of PCA component columns\n",
    "list = [*range(6, 48, 1)]\n",
    "#print(list)\n",
    "#Restore X back to full range of features\n",
    "X = Data.drop('actualleadtime',axis =1).values\n",
    "y = Data['actualleadtime'].values\n",
    "\n",
    "#QC\n",
    "#print(X[0, 6:48])\n",
    "#X[0, list]\n",
    "#columnListPCA = Data.columns.tolist()\n",
    "\n",
    "#splitting Train and Test \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-number",
   "metadata": {
    "id": "tamil-number"
   },
   "outputs": [],
   "source": [
    "# PCA standardization step 3 - standardize PCA components\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "transformer = ColumnTransformer(transformers=[('num', RobustScaler(), list)], remainder='passthrough')\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-coverage",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "id": "severe-coverage",
    "outputId": "589fb590-df59-49b0-ac47-c6188f8e0fdd"
   },
   "outputs": [],
   "source": [
    "# PCA standardization step 4 - QC\n",
    "inputShape = X_train.shape[1]\n",
    "print(X_train.shape)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "random.seed(10)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001,                   # minimium amount of change to count as an improvement\n",
    "    patience=20,                       # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model5 = keras.Sequential([\n",
    "    layers.Dense(1024, activation='relu', input_shape=[inputShape]), \n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "\n",
    "model5.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae',\n",
    ")\n",
    "\n",
    "history5 = model5.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=256,\n",
    "    epochs=500,\n",
    "    callbacks=[early_stopping],        # put your callbacks in a list\n",
    "    verbose=0,                         # turn off training log\n",
    ")\n",
    "\n",
    "# convert the training history to a dataframe\n",
    "history_df = pd.DataFrame(history5.history)\n",
    "# use Pandas native plot method\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))\n",
    "\n",
    "y_pred = model5.predict(X_test)\n",
    "print('MAE:     ', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('MSE:     ', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('RMSE:    ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('VarScore:',metrics.explained_variance_score(y_test,y_pred))\n",
    "print('R^2     :', metrics.r2_score(y_test, y_pred))\n",
    "# Visualizing Our predictions\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_test,y_pred)\n",
    "# Perfect predictions\n",
    "plt.plot(y_test,y_test,'r')\n",
    "\n",
    "\n",
    "#(52428, 55)\n",
    "#Minimum validation loss: 6.5822722340117625\n",
    "#MAE:      6.583061388649056\n",
    "#MSE:      68.36428226026061\n",
    "#RMSE:     8.268269604957291\n",
    "#VarScore: 0.004141823261248345\n",
    "#R^2     : -0.031058037221283863\n",
    "\n",
    "#Minimum validation loss: 6.579778779969114\n",
    "#MAE:      6.579778759241413\n",
    "#MSE:      68.33070947553436\n",
    "#RMSE:     8.266239137330492\n",
    "#VarScore: 0.004770350819703895\n",
    "#R^2     : -0.03055169840839156\n",
    "\n",
    "#(52428, 55)\n",
    "#Minimum validation loss: 6.578337165395665\n",
    "#MAE:      6.578565093263969\n",
    "#MSE:      68.48308737984802\n",
    "#RMSE:     8.27545088680055\n",
    "#VarScore: 0.004868143088059829\n",
    "#R^2     : -0.03284983506313499\n",
    "\n",
    "#(52428, 55)\n",
    "#Minimum validation loss: 6.583355809545921\n",
    "#MAE:      6.583355940078592\n",
    "#MSE:      68.39729229848054\n",
    "#RMSE:     8.270265551871992\n",
    "#VarScore: 0.0049065016496776526\n",
    "#R^2     : -0.03155588879070548\n",
    "\n",
    "#(52428, 55)\n",
    "#Minimum validation loss: 6.5828712485134355\n",
    "#MAE:      6.582871302401818\n",
    "#MSE:      68.44929316405572\n",
    "#RMSE:     8.27340879952488\n",
    "#VarScore: 0.004037667035531434\n",
    "#R^2     : -0.03234015666599199\n",
    "(52428, 55)\n",
    "Minimum validation loss: 6.585849285125732\n",
    "MAE:      6.585848741548834\n",
    "MSE:      68.5219444528118\n",
    "RMSE:     8.277798285342051\n",
    "VarScore: 0.0038387341517374107\n",
    "R^2     : -0.03343587057843056\n",
    "[<matplotlib.lines.Line2D at 0x7f0dbc358990>]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-olive",
   "metadata": {
    "id": "cosmetic-olive"
   },
   "source": [
    "But, we know that we had a better group of features to model,so lets use these again with the RobustScalar applied to the PCA components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-blood",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "appreciated-blood",
    "outputId": "390fcf64-ea25-4a81-e573-9fade04b0dc3"
   },
   "outputs": [],
   "source": [
    "# Categorical standardization step with reduced features from correlations - QC\n",
    "X = Data_corr.drop('actualleadtime',axis =1).values\n",
    "y = Data_corr['actualleadtime'].values\n",
    "\n",
    "print(Data_corr.columns)\n",
    "corrcolumnList = Data_corr.columns.tolist()\n",
    "corrdeepcopy = Data_corr.copy(deep=True)\n",
    "\n",
    "#\n",
    "list2 = [0, 1, 2, 6]\n",
    "#print(X[0, list2])\n",
    "#print(Data_corr.head(1))\n",
    "\n",
    "#splitting Train and Test \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=50)\n",
    "\n",
    "# PCA standardization step 3 - standardize PCA components\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "transformer = ColumnTransformer(transformers=[('num', RobustScaler(), list2)], remainder='passthrough')\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(y_train.shape)\n",
    "#print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-montreal",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "ceramic-montreal",
    "outputId": "7c32c937-0e54-4db9-abeb-1d1b1107a5df"
   },
   "outputs": [],
   "source": [
    "# Corr - PCA standardization - QC\n",
    "inputShape = X_train.shape[1]\n",
    "print(X_train.shape)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "random.seed(10)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001,                   # minimium amount of change to count as an improvement\n",
    "    patience=20,                       # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model6 = keras.Sequential([\n",
    "    layers.Dense(1024, activation='relu', input_shape=[inputShape]), \n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "\n",
    "model6.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae',\n",
    ")\n",
    "\n",
    "history6 = model6.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=256,\n",
    "    epochs=500,\n",
    "    callbacks=[early_stopping],        # put your callbacks in a list\n",
    "    verbose=0,                         # turn off training log\n",
    ")\n",
    "\n",
    "# convert the training history to a dataframe\n",
    "history_df = pd.DataFrame(history6.history)\n",
    "# use Pandas native plot method\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))\n",
    "\n",
    "y_pred = model6.predict(X_test)\n",
    "print('MAE:     ', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('MSE:     ', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('RMSE:    ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('VarScore:',metrics.explained_variance_score(y_test,y_pred))\n",
    "print('R^2     :', metrics.r2_score(y_test, y_pred))\n",
    "# Visualizing Our predictions\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_test,y_pred)\n",
    "# Perfect predictions\n",
    "plt.plot(y_test,y_test,'r')\n",
    "\n",
    "\n",
    "#(52428, 9)\n",
    "#Minimum validation loss: 5.438045465255881\n",
    "#MAE:      5.438045402472503\n",
    "#MSE:      54.70697851738233\n",
    "#RMSE:     7.396416599771968\n",
    "#VarScore: 0.20832859916762636\n",
    "#R^2     : 0.17491900700861462\n",
    "\n",
    "#(52428, 9)\n",
    "#Minimum validation loss: 5.450207921272104\n",
    "#MAE:      5.4511751146149905\n",
    "#MSE:      53.2457551332528\n",
    "#RMSE:     7.296968900389586\n",
    "#VarScore: 0.21203891300610045\n",
    "#R^2     : 0.19695692014938082\n",
    "\n",
    "#(52428, 9)\n",
    "#Minimum validation loss: 5.442438985787186\n",
    "#MAE:      5.4424390595847125\n",
    "#MSE:      54.24873196131605\n",
    "#RMSE:     7.365373850750283\n",
    "#VarScore: 0.21469537219145252\n",
    "#R^2     : 0.1818302006764193\n",
    "(52428, 9)\n",
    "Minimum validation loss: 5.454400062561035\n",
    "MAE:      5.454593881249583\n",
    "MSE:      54.32281156262853\n",
    "RMSE:     7.370401044897661\n",
    "VarScore: 0.2126950660502207\n",
    "R^2     : 0.18071294520613423\n",
    "[<matplotlib.lines.Line2D at 0x7f0dbe2966d0>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-drink",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "prompt-drink",
    "outputId": "2c3fc797-0b6e-4043-aa2e-fc90a8d5fb21"
   },
   "outputs": [],
   "source": [
    "# Now run with validation approach\n",
    "inputShape = X_train.shape[1]\n",
    "print(X_train.shape)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "random.seed(10)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001,                   # minimium amount of change to count as an improvement\n",
    "    patience=20,                       # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    " \n",
    "model7 = keras.Sequential([\n",
    "    layers.Dense(1024, activation='relu', input_shape=[inputShape]), \n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "\n",
    "model7.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae',\n",
    ")\n",
    "\n",
    "history7 = model7.fit(\n",
    "    X_train, y_train,\n",
    "#    validation_data=(X_test, y_test),\n",
    "    validation_split=0.20, \n",
    "    shuffle=True, \n",
    "    batch_size=256,\n",
    "    epochs=500,\n",
    "    callbacks=[early_stopping],        # put your callbacks in a list\n",
    "    verbose=0,                         # turn off training log\n",
    ")\n",
    "\n",
    "# convert the training history to a dataframe\n",
    "history_df = pd.DataFrame(history7.history)\n",
    "# use Pandas native plot method\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))\n",
    "\n",
    "y_pred = model7.predict(X_test)\n",
    "print('MAE:     ', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('MSE:     ', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('RMSE:    ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('VarScore:',metrics.explained_variance_score(y_test,y_pred))\n",
    "print('R^2     :', metrics.r2_score(y_test, y_pred))\n",
    "# Visualizing Our predictions\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_test,y_pred)\n",
    "# Perfect predictions\n",
    "plt.plot(y_test,y_test,'r')\n",
    "\n",
    "\n",
    "#(52428, 9)\n",
    "#Minimum validation loss: 5.406984850079327\n",
    "#MAE:      5.464944444405202\n",
    "#MSE:      53.89007596127871\n",
    "#RMSE:     7.340986034674001 - @256\n",
    "#VarScore: 0.2078638606317419\n",
    "#R^2     : 0.18723938715816035\n",
    "\n",
    "#Minimum validation loss: 5.655806328898824\n",
    "#MAE:      5.73160720036142\n",
    "#MSE:      59.1501619756141\n",
    "#RMSE:     7.69091424835917\n",
    "#VarScore: 0.1531305732989643\n",
    "#R^2     : 0.10790769841302206\n",
    "\n",
    "\n",
    "#(52428, 9)\n",
    "#Minimum validation loss: 5.40487624387943\n",
    "#MAE:      5.4650467362530835\n",
    "#MSE:      53.89647817690637\n",
    "#RMSE:     7.341422081375404\n",
    "#VarScore: 0.20204994398927567\n",
    "#R^2     : 0.18714283007219856\n",
    "\n",
    "#(52428, 9)\n",
    "#Minimum validation loss: 5.490564767308938\n",
    "#MAE:      5.569218715786834\n",
    "#MSE:      55.52829144063706\n",
    "#RMSE:     7.451730768126091\n",
    "#VarScore: 0.18194490853407075\n",
    "#R^2     : 0.16253211048022476\n",
    "\n",
    "#(52428, 9)\n",
    "#Minimum validation loss: 5.450915723317183\n",
    "#MAE:      5.527843021424255\n",
    "#MSE:      55.040430510997965\n",
    "#RMSE:     7.4189238108365805\n",
    "#VarScore: 0.19404366937924367\n",
    "#R^2     : 0.1698899429026537\n",
    "\n",
    "\n",
    "(52428, 9)\n",
    "Minimum validation loss: 5.402743816375732\n",
    "MAE:      5.4759828102818755\n",
    "MSE:      54.1524600662066\n",
    "RMSE:     7.358835510201774\n",
    "VarScore: 0.20499657311212205\n",
    "R^2     : 0.18328215640431278\n",
    "[<matplotlib.lines.Line2D at 0x7f0dbdccfc50>]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-separation",
   "metadata": {
    "id": "advance-separation"
   },
   "source": [
    "### Economic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-wrestling",
   "metadata": {
    "id": "elect-wrestling"
   },
   "outputs": [],
   "source": [
    "econ = pd.DataFrame(X_test)\n",
    "econ['actual'] = y_test\n",
    "econ['pred'] = y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-mirror",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "appropriate-mirror",
    "outputId": "53fd5fa1-2a1f-4415-d422-fd24c0cb9e49"
   },
   "outputs": [],
   "source": [
    "Data_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-adjustment",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "fitted-adjustment",
    "outputId": "e5c753f5-4a57-4313-e57d-07612f8411bd"
   },
   "outputs": [],
   "source": [
    "#econ[8]\n",
    "econ\n",
    "econ = econ.rename(columns={8: 'expected'})\n",
    "econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-kruger",
   "metadata": {
    "id": "aggregate-kruger"
   },
   "outputs": [],
   "source": [
    "#Error of model\n",
    "#Negative is too early\n",
    "econ['error_model'] = econ['pred'] - econ['actual']\n",
    "#Error of 'expected'\n",
    "#Negative is too early\n",
    "econ['error_expected'] = econ['expected'] - econ['actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-morrison",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "intellectual-morrison",
    "outputId": "137a95da-7d77-4d65-e44e-dffc5b22505c"
   },
   "outputs": [],
   "source": [
    "#Create cost for 'expected_leadtime'\n",
    "econ['expected_leadtime_cost'] = np.nan\n",
    "\n",
    "for index, row in econ.iterrows():\n",
    "    if (econ['error_expected'][index] > -1) & (econ['error_expected'][index] < 1): \n",
    "    # -1 to 1 weeks, $0\n",
    "        econ['expected_leadtime_cost'][index] = 0.00\n",
    "    elif (econ['error_expected'][index] >= 1) & (econ['error_expected'][index] < 2): \n",
    "    # 1 week, $400\n",
    "        econ['expected_leadtime_cost'][index] = 400.00\n",
    "    elif (econ['error_expected'][index] >= 2) & (econ['error_expected'][index] < 4): \n",
    "    # 2 weeks - 3 weeks, $600\n",
    "        econ['expected_leadtime_cost'][index] = 600.00  \n",
    "    elif (econ['error_expected'][index] >= 4) & (econ['error_expected'][index] < 8): \n",
    "    # 4 weeks - 7 weeks, $1,000 \n",
    "        econ['expected_leadtime_cost'][index] = 1000.00\n",
    "    elif (econ['error_expected'][index] >= 8): \n",
    "    # 8 weeks or more, $4,000\n",
    "        econ['expected_leadtime_cost'][index] = 4000.00      \n",
    "    else: \n",
    "    # all negative weeks (too early), $400/week \n",
    "        econ['expected_leadtime_cost'][index] = np.floor(abs(econ['error_expected'][index]))*400.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-springfield",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "comparable-springfield",
    "outputId": "23fc2942-1a14-49ba-e29e-786844085a07"
   },
   "outputs": [],
   "source": [
    "#Create cost for model\n",
    "econ['modeledcost'] = np.nan\n",
    "\n",
    "for index, row in econ.iterrows():\n",
    "    if (econ['error_model'][index] > -1) & (econ['error_model'][index] < 1): \n",
    "    # -1 to 1 weeks, $0\n",
    "        econ['modeledcost'][index] = 0.00\n",
    "    elif (econ['error_model'][index] >= 1) & (econ['error_model'][index] < 2): \n",
    "    # 1 week, $400\n",
    "        econ['modeledcost'][index] = 400.00\n",
    "    elif (econ['error_model'][index] >= 2) & (econ['error_model'][index] < 4): \n",
    "    # 2 weeks - 3 weeks, $600\n",
    "        econ['modeledcost'][index] = 600.00  \n",
    "    elif (econ['error_model'][index] >= 4) & (econ['error_model'][index] < 8): \n",
    "    # 4 weeks - 7 weeks, $1,000 \n",
    "        econ['modeledcost'][index] = 1000.00\n",
    "    elif (econ['error_model'][index] >= 8): \n",
    "    # 8 weeks or more, $4,000\n",
    "        econ['modeledcost'][index] = 4000.00      \n",
    "    else: \n",
    "    # all negative weeks (too early), $400/week \n",
    "        econ['modeledcost'][index] = np.floor(abs(econ['error_model'][index]))*400.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-competition",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "designing-competition",
    "outputId": "d962bd44-0e8e-4277-f6a6-ebc4c34397dd"
   },
   "outputs": [],
   "source": [
    "#Data_for_econ.head(10)\n",
    "#np.floor(Data_for_econ['error_modeledleadtime'].iloc[1])\n",
    "(econ['expected_leadtime_cost'].sum() - econ['modeledcost'].sum()) / econ['expected_leadtime_cost'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-appendix",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imperial-appendix",
    "outputId": "b2e7ee0d-79e0-4bee-fc4e-8a3191eb6d66"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.setlocale( locale.LC_ALL, '' )\n",
    "print('RMSE:                     ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('MAE:                      ', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Expected:                  ' + str(locale.currency(econ['expected_leadtime_cost'].sum(), grouping=True )))\n",
    "print('Neural Net:                ' + str(locale.currency(econ['modeledcost'].sum(), grouping=True )))\n",
    "print('Savings from using model:  ' + str(locale.currency((econ['expected_leadtime_cost'].sum() - econ['modeledcost'].sum()), grouping=True )))\n",
    "print('%Savings from using model: ' + str((econ['expected_leadtime_cost'].sum() - econ['modeledcost'].sum()) / econ['expected_leadtime_cost'].sum()))\n",
    "\n",
    "#Neural Net:               $115,159,600.00\n",
    "#Expected                  $148,529,400.00\n",
    "#Savings from using model: $33,369,800.00\n",
    "\n",
    "\n",
    "\n",
    "RMSE:                      7.358835510201774\n",
    "MAE:                       5.4759828102818755\n",
    "Expected:                  $29,717,400.00\n",
    "Neural Net:                $23,376,000.00\n",
    "Savings from using model:  $6,341,400.00\n",
    "%Savings from using model: 0.21339013507238183"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-practice",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amateur-practice",
    "outputId": "85fa6f34-aaa5-41f5-d6cf-28dffad3defe"
   },
   "outputs": [],
   "source": [
    "print('RMSE OF ARROW: ', np.sqrt(metrics.mean_squared_error(econ['actual'], econ['expected'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-subdivision",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mineral-subdivision",
    "outputId": "fa93cc72-d341-431e-f739-1567cdf87ad1"
   },
   "outputs": [],
   "source": [
    "RMSE OF ARROW:  10.065229386516192"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-beginning",
   "metadata": {
    "id": "compatible-beginning"
   },
   "source": [
    "### END"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "compatible-beginning"
   ],
   "name": "Final_KerasNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
